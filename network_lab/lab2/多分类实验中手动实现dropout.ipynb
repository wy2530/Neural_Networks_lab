{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58ecf112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"  #防止jupyter崩溃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c273f28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "#下载MNIST手写数据集\n",
    "mnist_train = torchvision.datasets.MNIST(root='./Datasets/MNIST', train=True,\n",
    "download=True, transform=transforms.ToTensor())\n",
    "mnist_test = torchvision.datasets.MNIST(root='./Datasets/MNIST', train=False,\n",
    "download=True, transform=transforms.ToTensor())\n",
    "#读取数据\n",
    "batch_size = 32\n",
    "train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True,\n",
    "num_workers=0)\n",
    "test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False,\n",
    "num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "088a5b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(X,drop_prob):\n",
    "    X=X.float()\n",
    "    assert 0 <= drop_prob <=1\n",
    "    keep_prob = 1-drop_prob\n",
    "    if keep_prob == 0:\n",
    "        return torch.zeros_like(X)\n",
    "    mask = (torch.rand(X.shape)<keep_prob).float()\n",
    "    return mask*X/keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86e4672",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=torch.arange(10).view(2,5)\n",
    "print(dropout(X,0),'\\n')\n",
    "print(dropout(X,0.5),'\\n')\n",
    "print(dropout(X,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb885698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化参数\n",
    "num_inputs,num_outputs,num_hiddens1,num_hiddens2 = 784,10,256,256\n",
    "\n",
    "W1 = torch.tensor(np.random.normal(0, 0.01, size=(num_hiddens1,num_inputs)), dtype=torch.float32,requires_grad=True)\n",
    "b1 = torch.zeros(num_hiddens1,requires_grad=True)\n",
    "W2 = torch.tensor(np.random.normal(0, 0.01, size=(num_hiddens2,num_hiddens1)), dtype=torch.float32,requires_grad=True)\n",
    "b2 = torch.zeros(num_hiddens2,requires_grad=True)\n",
    "W3 = torch.tensor(np.random.normal(0, 0.01, size=(num_outputs,num_hiddens2)), dtype=torch.float32,requires_grad=True)\n",
    "b3 = torch.zeros(num_outputs,requires_grad=True)\n",
    "params =[W1,b1,W2,b2,W3,b3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ade99bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_prob1,drop_prob2=0.2,0.5\n",
    "\n",
    "def net(X,is_training=True):\n",
    "    X=X.view(-1,num_inputs)\n",
    "    H1=(torch.matmul(X,W1.t())+b1).relu()\n",
    "    if is_training:\n",
    "        H1=dropout(H1,drop_prob1)\n",
    "    H2=(torch.matmul(H1,W2.t())+b2).relu()\n",
    "    if is_training:\n",
    "        H2=dropout(H2,drop_prob2)\n",
    "    return torch.matmul(H2,W3.t())+b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "050a0247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter,net):\n",
    "    acc_sum,n=0.0,0\n",
    "    for X,y in data_iter:\n",
    "        acc_sum+=(net(X,is_training=False).argmax(dim=1)==y).float().sum().item()\n",
    "        n+=y.shape[0]\n",
    "    return acc_sum/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f43c5e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义随机梯度下降法\n",
    "def SGD(paras,lr):\n",
    "    for param in params:\n",
    "        param.data -= lr * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52569d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试集loss\n",
    "def evaluate_loss(data_iter,net):\n",
    "    acc_sum,loss_sum,n = 0.0,0.0,0\n",
    "    for X,y in data_iter:\n",
    "        y_hat = net(X)\n",
    "        acc_sum += (y_hat.argmax(dim=1)==y).sum().item()\n",
    "        l = loss(y_hat,y) # l是有关小批量X和y的损失\n",
    "        loss_sum += l.sum().item()*y.shape[0]\n",
    "        n+=y.shape[0]\n",
    "    return acc_sum/n,loss_sum/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41c14c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义模型训练函数\n",
    "def train(net,train_iter,test_iter,loss,num_epochs,batch_size,params=None,lr=None,optimizer=None):\n",
    "    train_ls = []\n",
    "    test_ls = []\n",
    "    for epoch in range(num_epochs): # 训练模型一共需要num_epochs个迭代周期\n",
    "        train_l_sum, train_acc_num,n = 0.0,0.0,0\n",
    "        # 在每一个迭代周期中，会使用训练数据集中所有样本一次\n",
    "        for X, y in train_iter: # x和y分别是小批量样本的特征和标签\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y).sum() # l是有关小批量X和y的损失\n",
    "            #梯度清零\n",
    "            if optimizer is not None:\n",
    "                optimizer.zero_grad()\n",
    "            elif params is not None and params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "            l.backward() # 小批量的损失对模型参数求梯度\n",
    "            if optimizer is None:\n",
    "                SGD(params,lr)\n",
    "            else:\n",
    "                optimizer.step()\n",
    "            #计算每个epoch的loss\n",
    "            train_l_sum += l.item()*y.shape[0]\n",
    "            #计算训练样本的准确率\n",
    "            train_acc_num += (y_hat.argmax(dim=1)==y).sum().item()\n",
    "            #每一个epoch的所有样本数\n",
    "            n+= y.shape[0]\n",
    "        train_ls.append(train_l_sum/n)\n",
    "        test_acc,test_l = evaluate_loss(test_iter,net)\n",
    "        test_ls.append(test_l)\n",
    "        print('epoch %d, train_loss %.6f,test_loss %f,train_acc %.6f,test_acc %.6f'%(epoch+1, train_ls[epoch],test_ls[epoch],train_acc_num/n,test_acc))\n",
    "    return train_ls,test_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbfa2063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train_loss 0.186851,test_loss 0.148770,train_acc 0.944317,test_acc 0.955300\n",
      "epoch 2, train_loss 0.133903,test_loss 0.139640,train_acc 0.960050,test_acc 0.958000\n",
      "epoch 3, train_loss 0.105571,test_loss 0.111442,train_acc 0.967933,test_acc 0.965400\n",
      "epoch 4, train_loss 0.090396,test_loss 0.107504,train_acc 0.972850,test_acc 0.968100\n",
      "epoch 5, train_loss 0.079016,test_loss 0.106666,train_acc 0.976083,test_acc 0.967500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.18685149675011634,\n",
       "  0.13390267499809463,\n",
       "  0.10557074166027208,\n",
       "  0.09039612401618312,\n",
       "  0.07901648317569246],\n",
       " [0.1487695613734424,\n",
       "  0.13963997040428222,\n",
       "  0.11144194802977145,\n",
       "  0.10750422503910959,\n",
       "  0.10666603716928512])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs,lr,batch_size=5,0.1,128\n",
    "loss=torch.nn.CrossEntropyLoss()\n",
    "train(net,train_iter,test_iter,loss,num_epochs,batch_size,params,lr,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf18cc10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
