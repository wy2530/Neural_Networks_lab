{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim\n",
    "from torch.nn import init\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"  #防止jupyter崩溃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自定义数据\n",
    "num_inputs = 500\n",
    "num_examples = 10000\n",
    "true_w = torch.ones(500,1)*0.0056\n",
    "true_b = 0.028\n",
    "x_features = torch.tensor(np.random.normal(0, 1, (num_examples, num_inputs)), dtype=torch.float)\n",
    "y_labels = torch.mm(x_features,true_w) + true_b\n",
    "y_labels += torch.tensor(np.random.normal(0, 0.01, size=y_labels.size()), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#实现FlattenLayer层\n",
    "class FlattenLayer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "         super(FlattenLayer, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "#模型定义和参数初始化\n",
    "num_hiddens,num_outputs = 256,1\n",
    "net = nn.Sequential(\n",
    "        FlattenLayer(),\n",
    "        nn.Linear(num_inputs,num_hiddens),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(num_hiddens,num_outputs)\n",
    "        )\n",
    "\n",
    "for params in net.parameters():\n",
    "    init.normal_(params,mean=0,std=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kfold_data(k,i,X,y):\n",
    "    \"\"\"\n",
    "    k:一个K折\n",
    "    i:第几折\n",
    "    X:\n",
    "    \"\"\"\n",
    "    fold_size=X.shape[0]//k  # X是数据集，将所有数据集分为K份\n",
    "    val_start=i*fold_size  #\n",
    "    \n",
    "    if i!=k-1: # 不是最后一折\n",
    "        val_end=(i+1)*fold_size   \n",
    "        \n",
    "        ## 验证集\n",
    "        X_valid,y_valid =X[val_start:val_end],y[val_start:val_end]\n",
    "        ## 训练集\n",
    "        X_train=torch.cat((X[0:val_start],X[val_end:]),dim=0)\n",
    "        y_train=torch.cat((y[0:val_start],y[val_end:]),dim=0)\n",
    "    else:\n",
    "        X_valid,y_valid=X[val_start:],y[val_start:]  # 若不能整除，将多的样本放在最后一折里\n",
    "        X_train=X[0:val_start]\n",
    "        y_train=y[0:val_start]\n",
    "    return X_train,y_train,X_valid,y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义模型训练函数\n",
    "def train(net,train_iter,test_iter,loss,num_epochs,batch_size,trainfeatures,trainlabels,testfeatures,testlabels,params=None,lr=None,optimizer=None):\n",
    "    train_ls = []\n",
    "    test_ls = []\n",
    "    for epoch in range(num_epochs): # 训练模型一共需要num_epochs个迭代周期\n",
    "        train_l_sum,n = 0.0,0\n",
    "        # 在每一个迭代周期中，会使用训练数据集中所有样本一次\n",
    "        for X, y in train_iter: # x和y分别是小批量样本的特征和标签\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y.view(-1,1)) # l是有关小批量X和y的损失\n",
    "            #梯度清零\n",
    "            if optimizer is not None:\n",
    "                optimizer.zero_grad()\n",
    "            elif params is not None and params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "            l.backward() # 小批量的损失对模型参数求梯度\n",
    "            if optimizer is None:\n",
    "                SGD(params,lr)\n",
    "            else:\n",
    "                optimizer.step()\n",
    "        train_labels = trainlabels\n",
    "        test_labels = testlabels\n",
    "        train_ls.append(loss(net(trainfeatures),train_labels).item())\n",
    "        test_ls.append(loss(net(testfeatures),test_labels).item())\n",
    "    print('epoch %d, train_loss %.6f,test_loss %f'%(epoch+1, train_ls[epoch],test_ls[epoch]))\n",
    "    return train_ls[epoch],test_ls[epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(k,X_train,y_train):\n",
    "    train_loss_sum,valid_loss_sum= 0,0\n",
    "    for i in range(k):\n",
    "        print(\"第\",i+1,\"折验证结果\")\n",
    "        X_train,y_train,X_valid,y_valid=get_kfold_data(k,i,X_train,y_train)  # 获取K折的训练集和验证集\n",
    "        \n",
    "        train_dataset = Data.TensorDataset(X_train, y_train) \n",
    "        train_iter = Data.DataLoader(\n",
    "                dataset=train_dataset, # torch TensorDataset format\n",
    "                batch_size=batch_size, # mini batch size\n",
    "                shuffle=True, # 是否打乱数据 (训练集一般需要进行打乱)\n",
    "                num_workers=0, # 多线程来读数据， 注意在Windows下需要设置为0\n",
    "                    )\n",
    "        \n",
    "        test_dataset = Data.TensorDataset(X_valid, y_valid)\n",
    "        test_iter = Data.DataLoader(\n",
    "                dataset=test_dataset, # torch TensorDataset format\n",
    "                batch_size=batch_size, # mini batch size\n",
    "                shuffle=True, # 是否打乱数据 (训练集一般需要进行打乱)\n",
    "                num_workers=0, # 多线程来读数据， 注意在Windows下需要设置为0\n",
    "                    )\n",
    "        lr = 0.01\n",
    "        #损失函数和优化器\n",
    "        loss = torch.nn.MSELoss()\n",
    "        optimizer = torch.optim.SGD(net.parameters(),lr)\n",
    "        for params in net.parameters():\n",
    "            init.normal_(params,mean=0,std=0.01) #每轮训练都重新初始化参数\n",
    "        train_loss,test_loss = train(net,train_iter,test_iter,loss,num_epochs,batch_size,X_train,y_train,X_valid,y_valid,net.parameters,lr,optimizer)\n",
    "        train_loss_sum+=train_loss\n",
    "        valid_loss_sum+=test_loss\n",
    "    print(\"\\n最终k折交叉验证结果：\")\n",
    "    print(\"average train loss:{:.4f},average valis loss:{:.4f}\".format(train_loss_sum/k,valid_loss_sum/k))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 1 折验证结果\n",
      "epoch 20, train_loss 0.000743,test_loss 0.001140\n",
      "第 2 折验证结果\n",
      "epoch 20, train_loss 0.000795,test_loss 0.001315\n",
      "第 3 折验证结果\n",
      "epoch 20, train_loss 0.000870,test_loss 0.001377\n",
      "第 4 折验证结果\n",
      "epoch 20, train_loss 0.000914,test_loss 0.001414\n",
      "第 5 折验证结果\n",
      "epoch 20, train_loss 0.001056,test_loss 0.001804\n",
      "第 6 折验证结果\n",
      "epoch 20, train_loss 0.001288,test_loss 0.002159\n",
      "第 7 折验证结果\n",
      "epoch 20, train_loss 0.001742,test_loss 0.003139\n",
      "第 8 折验证结果\n",
      "epoch 20, train_loss 0.002139,test_loss 0.003518\n",
      "第 9 折验证结果\n",
      "epoch 20, train_loss 0.003209,test_loss 0.004710\n",
      "第 10 折验证结果\n",
      "epoch 20, train_loss 0.003853,test_loss 0.005458\n",
      "\n",
      "最终k折交叉验证结果：\n",
      "average train loss:0.0017,average valis loss:0.0026\n"
     ]
    }
   ],
   "source": [
    "#训练次数和学习率\n",
    "num_epochs = 20\n",
    "k_fold(10,x_features,y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python37464bitpytorchconda0a4842cb181546f0bba59e31fe04aadb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
